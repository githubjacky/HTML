\documentclass[12pt,a4paper]{article}

\usepackage[a4paper,text={16.5cm,25.2cm},centering]{geometry}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Prob}{\mathbb{P}}

\usepackage{bbm}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{microtype}
\usepackage{hyperref}
\setlength{\parindent}{0pt}
\setlength{\parskip}{1.2ex}

\hypersetup
       {   pdfauthor = { Hsiu Hsuan Yeh },
           pdftitle={ HW3 for Machine Learning },
           colorlinks=TRUE,
           linkcolor=black,
           citecolor=blue,
           urlcolor=blue
       }

\title{ HW3 for Machine Learning }

\author{ Hsiu Hsuan Yeh }

\date{ 27th April 2023 }

\usepackage{upquote}
\usepackage{listings}
\usepackage{xcolor}
\lstset{
    basicstyle=\ttfamily\footnotesize,
    upquote=true,
    breaklines=true,
    breakindent=0pt,
    keepspaces=true,
    showspaces=false,
    columns=fullflexible,
    showtabs=false,
    showstringspaces=false,
    escapeinside={(*@}{@*)},
    extendedchars=true,
}
\newcommand{\HLJLt}[1]{#1}
\newcommand{\HLJLw}[1]{#1}
\newcommand{\HLJLe}[1]{#1}
\newcommand{\HLJLeB}[1]{#1}
\newcommand{\HLJLo}[1]{#1}
\newcommand{\HLJLk}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkc}[1]{\textcolor[RGB]{59,151,46}{\textit{#1}}}
\newcommand{\HLJLkd}[1]{\textcolor[RGB]{214,102,97}{\textit{#1}}}
\newcommand{\HLJLkn}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkp}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkr}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLkt}[1]{\textcolor[RGB]{148,91,176}{\textbf{#1}}}
\newcommand{\HLJLn}[1]{#1}
\newcommand{\HLJLna}[1]{#1}
\newcommand{\HLJLnb}[1]{#1}
\newcommand{\HLJLnbp}[1]{#1}
\newcommand{\HLJLnc}[1]{#1}
\newcommand{\HLJLncB}[1]{#1}
\newcommand{\HLJLnd}[1]{\textcolor[RGB]{214,102,97}{#1}}
\newcommand{\HLJLne}[1]{#1}
\newcommand{\HLJLneB}[1]{#1}
\newcommand{\HLJLnf}[1]{\textcolor[RGB]{66,102,213}{#1}}
\newcommand{\HLJLnfm}[1]{\textcolor[RGB]{66,102,213}{#1}}
\newcommand{\HLJLnp}[1]{#1}
\newcommand{\HLJLnl}[1]{#1}
\newcommand{\HLJLnn}[1]{#1}
\newcommand{\HLJLno}[1]{#1}
\newcommand{\HLJLnt}[1]{#1}
\newcommand{\HLJLnv}[1]{#1}
\newcommand{\HLJLnvc}[1]{#1}
\newcommand{\HLJLnvg}[1]{#1}
\newcommand{\HLJLnvi}[1]{#1}
\newcommand{\HLJLnvm}[1]{#1}
\newcommand{\HLJLl}[1]{#1}
\newcommand{\HLJLld}[1]{\textcolor[RGB]{148,91,176}{\textit{#1}}}
\newcommand{\HLJLs}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsa}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsb}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsc}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsd}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsdB}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsdC}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLse}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLsh}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsi}[1]{#1}
\newcommand{\HLJLso}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLsr}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLss}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLssB}[1]{\textcolor[RGB]{201,61,57}{#1}}
\newcommand{\HLJLnB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnbB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnfB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnh}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLni}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnil}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLnoB}[1]{\textcolor[RGB]{59,151,46}{#1}}
\newcommand{\HLJLoB}[1]{\textcolor[RGB]{102,102,102}{\textbf{#1}}}
\newcommand{\HLJLow}[1]{\textcolor[RGB]{102,102,102}{\textbf{#1}}}
\newcommand{\HLJLp}[1]{#1}
\newcommand{\HLJLc}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLch}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcm}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcp}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcpB}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcs}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLcsB}[1]{\textcolor[RGB]{153,153,119}{\textit{#1}}}
\newcommand{\HLJLg}[1]{#1}
\newcommand{\HLJLgd}[1]{#1}
\newcommand{\HLJLge}[1]{#1}
\newcommand{\HLJLgeB}[1]{#1}
\newcommand{\HLJLgh}[1]{#1}
\newcommand{\HLJLgi}[1]{#1}
\newcommand{\HLJLgo}[1]{#1}
\newcommand{\HLJLgp}[1]{#1}
\newcommand{\HLJLgs}[1]{#1}
\newcommand{\HLJLgsB}[1]{#1}
\newcommand{\HLJLgt}[1]{#1}


\begin{document}

\maketitle

\section{Multiple Choice}
\subsection{1. (b)}
\[
a(2*\frac{N}{K})\frac{K(K-1)}{2} = a(K-1)N
\]
\subsection{2. (d)}
since collinearity exists between $x_2, x_6, x_1$, it's impossible to shatter all six inputs.

\subsection{3. (c)}
\[
z_1 = [1, 0, 0, 0, 0, 0]^T,
z_2 = [1, 4, 0, 16, 0, 0]^T,
z_3 = [1, -4, 0, 16, 0, 0]^T
\]
\[
z_4 = [1, 0, 2, 0, 0, 4]^T
z_5 = [1, 0, -2, 0, 0, 4]^T
\]
\begin{itemize}
\item $w_1 \text{ and } w_4$ can separate all examples


\item $w_2$ fail to separate $z_2, z_3, z_4, z_5$


\item $w_3$ fail to separate $z_4, z_5$

\end{itemize}
\subsection{4. (b)}
\begin{itemize}
\item $X'_{N*d+1} = X_{N*d+1}\Gamma_{d+1*d+1}^T$


\item $w_{lin} = (X^TX)^{-1}X^Ty$

\end{itemize}
\[
\tilde{w} = 
    (X'^TX')^{-1}X'^Ty = 
    (\Gamma X^TX\Gamma^T)^{-1}\Gamma X^Ty =
    (\Gamma^T)^{-1}(X^TX)^{-1}\Gamma^{-1}\Gamma(X^Ty) = 
    (\Gamma^T)^{-1}w_{lin}
\]
\begin{itemize}
\item $w_{lin} = \Gamma^T\tilde{w}$

\end{itemize}
$\pagebreak$

\begin{itemize}
\item $E_{in}(w_{lin}) = \frac{1}{N}(w_{lin}^TX^TXw_{lin} - 2w_{lin}^TX^Ty + y^Ty)$

\end{itemize}
\[
E_{in}(\tilde{w}) =
    \frac{1}{N}(\tilde{w}^TX'^TX'\tilde{w} - 2\tilde{w}^TX'^Ty + y^Ty) =
    \frac{1}{N}(w_{lin}^T\Gamma^{-1}\Gamma X^TX\Gamma^T(\Gamma^T)^{-1}w_{lin} - 2w_{lin}^T\Gamma^{-1}\Gamma X^Ty + y^Ty)
\]
\[
E_{in}(\tilde{w}) = 
    \frac{1}{N}(w_{lin}^TX^TXw_{lin} - 2w_{lin}^TX^Ty + y^Ty) = 
    E_{in}(w_{lin})
\]
\subsection{5. (b)}
\begin{itemize}
\item $m_{H_k}(N) = 2N$


\item $H = \cup_{k=1}^dH_k$

\end{itemize}
\[
m_H(N)\le d2N, 2^{d_{vc}} \le m_H(d_{vc}) \le d2d_{vc}
\]
\[
d_{vc} \le 1+log_2d_{vc}+log_2d \le 1+\frac{d_{vc}}{2}+log_2d
\]
\[
\Rightarrow \frac{d_{vc}}{2} \le 1+log_2d, d_{vc} \le 2(1+log_2d)
\]
\subsection{6. (c)}
by definition, $Z_{N*N}$ is an identity matrix

\begin{itemize}
\item $\tilde{w} = (Z^TZ)^{-1}Z^Ty = y$, $\Rightarrow \tilde{w_n} = y_n$


\item based on the previous couclusion, $E_{in}(g) = \frac{1}{N}(\tilde{w}^TZ^TZ\tilde{w} - 2\tilde{w}^TZ^Ty + y^Ty) = \frac{1}{N}(y^Ty - 2y^Ty + y^Ty) = 0$


\item $\Phi(X_{N*d}) \neq 2I_{N*N}$, where I is an identity matrix.


\item by the definition of the transformation rule: $g(x) = 0$ on those $x \neq x_n$ for any n

\end{itemize}
\subsection{7. (e)}
\begin{itemize}
\item $E_{aug}(w) = E_{in}(w) + \frac{\pi}{3}||w||_1 = E_{in}(w) + ||w||_1$

\end{itemize}
\[
\nabla E_{aug}(w) = 
    \nabla E_{in}(w) +
    \begin{bmatrix}
        sign(w_0) \\
        sign(w_1) \\
    \end{bmatrix} = 
    \begin{bmatrix}
        0 \\
        0 \\
    \end{bmatrix}
\]
\[
\nabla E_{in}(w) = 
    \frac{2}{3}(X^TXw-X^Ty) = 
    \frac{2}{3}(
    \begin{bmatrix}
        1 & 1 & 1 \\
        2 & 3 & -2 \\
    \end{bmatrix}
    \begin{bmatrix}
        1 & 2 \\
        1 & 3 \\
        1 & -2 \\
    \end{bmatrix}
    \begin{bmatrix}
        w_0 \\
        w_1 \\
    \end{bmatrix} - 
    \begin{bmatrix}
        1 & 1 & 1 \\
        2 & 3 & -2 \\
    \end{bmatrix}
    \begin{bmatrix}
        1 \\
        0 \\
        2 \\
    \end{bmatrix} 
    )
\]
\[
\nabla E_{aug}(w) =
    \nabla E_{in}(w) +
    \begin{bmatrix}
        sign(w_0) \\
        sign(w_1) \\
    \end{bmatrix} = 
    \begin{bmatrix}
        2w_0+2w_1-2 \\
        2w_0+\frac{34}{3}w_1+\frac{4}{3}
    \end{bmatrix} +
        \begin{bmatrix}
        sign(w_0) \\
        sign(w_1) \\
    \end{bmatrix} = 
    \begin{bmatrix}
        0 \\
        0 \\
    \end{bmatrix}
\]
\[
\Rightarrow \frac{28}{3}w_1+\frac{10}{3} + (sign(w_1)-sign(w_0)) = 0
\]
$\pagebreak$

\[
sign(w_1)-sign(w_0) = 
\begin{cases}
    0  &  w_0=\frac{13}{7}, w_1=\frac{-5}{14} \\
    2  &  w_0=\frac{29}{14}, w_1=\frac{-4}{7} \\
    -2 &  w_0=\frac{9}{14}, w_1=\frac{-1}{7}
\end{cases}
\]
\begin{itemize}
\item th contradiction exists when $sign(w_1)-sign(w_0)=0, 2$


\item $||w||_1 = |w_0| + |w_1| = |\frac{9}{14}|+|\frac{-1}{7}| = \frac{11}{14}$

\end{itemize}
\[
E_{in}(w) = 
    \frac{1}{3}(Xw-y)^T(Xw-y) = 
    \frac{1}{3}(
        \begin{bmatrix}
            1 & 2 \\
            1 & 3 \\
            1 & -2 \\
        \end{bmatrix}
        \begin{bmatrix}
            \frac{9}{14} \\
            \frac{-1}{7}
        \end{bmatrix} - 
        \begin{bmatrix}
            1 \\
            0 \\
            2
        \end{bmatrix}
    )^T
    (
        \begin{bmatrix}
            1 & 2 \\
            1 & 3 \\
            1 & -2 \\
        \end{bmatrix}
        \begin{bmatrix}
            \frac{9}{14} \\
            \frac{-1}{7}
        \end{bmatrix} - 
        \begin{bmatrix}
            1 \\
            0 \\
            2
        \end{bmatrix}
    ) = \frac{105}{196}
\]
\[
\Rightarrow E_{aug}(w) = E_{in}(w) + ||w||_1 = \frac{259}{196} \approx 1.32
\]
\subsection{8. (b)}
\begin{itemize}
\item $E_{aug}(w) = E_{in}(w) + \frac{\lambda}{2}||w||_2^2$


\item find $\lambda$ such that $w_0 + w_1 = 4$

\end{itemize}
\[
\nabla E_{aug}(w) = 
    \nabla E_{in}(w) +
    \lambda
    \begin{bmatrix}
        w_0 \\
        w_1
    \end{bmatrix} = 
    \begin{bmatrix}
        0 \\
        0
    \end{bmatrix}
\]
\[
\nabla E_{in}(w) = 
    \frac{2}{2}(X^TXw-X^Ty) = 
    \begin{bmatrix}
        1 & 1  \\
        2 & -2
    \end{bmatrix}
    \begin{bmatrix}
        1 & 2  \\
        1 & -2
    \end{bmatrix}
    \begin{bmatrix}
        w_0 \\
        w_1
    \end{bmatrix} -
    \begin{bmatrix}
        1 & 1  \\
        2 & -2
    \end{bmatrix}
    \begin{bmatrix}
        9 \\
        -1
    \end{bmatrix} = 
    \begin{bmatrix}
        2w_0 - 8 \\
        8w_1 - 20
    \end{bmatrix}
\]
\[
\Rightarrow 
\begin{bmatrix}
    2w_0-8+\lambda w_0 \\
    8w_1-20+\lambda w_1
\end{bmatrix} = 
\begin{bmatrix}
    0 \\
    0
\end{bmatrix},
\]
\[
\Rightarrow
\begin{cases}
    (2+\lambda)w_0 = 8 \\
    (8+\lambda)w_1 = 20
\end{cases}
\Rightarrow
\begin{cases}
    w_0 = \frac{8}{2+\lambda} \\
    w_1 = \frac{20}{8+\lambda}
\end{cases}
\]
\[
\frac{8}{2+\lambda} + \frac{20}{8+\lambda} = 4, \lambda^2+3\lambda-10=0, \lambda=-5, 2
\]
since $\lambda > 0, \lambda = 2$

\subsection{9. (b)}
\begin{itemize}
\item $\nabla E_{aug}(w) = \nabla E_{in}(w) + \frac{2\lambda}{N}w$

\end{itemize}
\[
w_t-\eta\nabla E_{aug}(w_t) = 
    w_t-\eta(\nabla E_{in}(w_t) + \frac{2\lambda}{N}w_t) =
    (1-\frac{2\eta\lambda}{N})w_t - \eta\nabla E_{in}(w_t)
\]
\subsection{10. (b)}
\[
||Xw-y||^2 + ||\tilde{X}w-\tilde{y}||^2 = ||Xw-y||^2 + \lambda||w||^2,
\Rightarrow
\begin{cases}
    \tilde{X} = \sqrt{\lambda}I_{d+1} \\
    \tilde{y} = 0
\end{cases}
\]
$\pagebreak$

\subsection{11. (c)}
\[
\E(X_h^TX_h) = 
    \E(\Sigma_{i=1}^Nx_ix_i^T + \Sigma_{i=1}^N\tilde{x}_i\tilde{x}_i^T) =
    \Sigma_{i=1}^Nx_ix_i^T + \Sigma_{i=1}^N\E(\tilde{x}_i\tilde{x}_i^T) = 
    X^TX + \Sigma_{i=1}^N\E((x_i+\epsilon_i)(x_i+\epsilon_i)^T)
\]
\[
= 
    X^TX + \Sigma_{i=1}^N\E(x_ix_i^T + x_i\epsilon_i^T + \epsilon_i^Tx_i + \epsilon_i\epsilon_i^T) = 
    X^TX + \Sigma_{i=1}^Nx_ix_i^T 
\]
\[
+ \Sigma_{i=1}^Nx_i\E(\epsilon_i)^T + \Sigma_{i=1}^N\E(\epsilon_i)x_i^T + \Sigma_{i=1}^N\E((\epsilon_i-0)(\epsilon_i-0)^T)
\]
\[
\Rightarrow \E(X_h^TX_h) = 2X^TX + \Sigma_{i=1}^N\frac{r^2}{3}I_{d+1} = 2X^TX + \frac{N}{3}r^2I_{d+1}
\]
\subsection{12. (b)}
\begin{itemize}
\item $y^\ast = \frac{(\Sigma_{n=1}^Ny_n)+K}{N+2K}$, $Ny^\ast = \Sigma_{n=1}^N y_n + (1-2y^\ast)K$

\end{itemize}
\[
\frac{\partial}{\partial y}(\frac{1}{N}\Sigma_{n=1}^N(y-y_n)^2 + \frac{\lambda}{N}\Omega(y)) = 
    \frac{1}{N}\Sigma_{n=1}^N2(y-y_n) + \frac{\lambda}{N}\Omega'(y) = 
    2y - \frac{2}{N}\Sigma_{n=1}^Ny_n + \frac{\lambda}{N}\Omega'(y) = 0
\]
\[
2y = \frac{2}{N}\Sigma_{n=1}^Ny_n - \frac{\lambda}{N}\Omega'(y),
Ny = \Sigma_{n=1}^Ny_n - \frac{\lambda}{2}\Omega'(y)
\]
\[
\Rightarrow - \frac{\lambda}{2}\Omega'(y) = (1-2y)K, \Omega(y) = \frac{2K}{\lambda}(y-0.5)^2
\]
$\pagebreak$

\section{Coding}


\subsection{13. (c)}

\begin{lstlisting}
(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{read{\_}data}@*)(*@\HLJLp{(}@*)(*@\HLJLs{"{}../train.txt"{}}@*)(*@\HLJLp{)}@*)

(*@\HLJLnd{@printf}@*)(*@\HLJLp{(}@*)
    (*@\HLJLs{"{}mean}@*) (*@\HLJLs{squared}@*) (*@\HLJLs{error:}@*) (*@\HLJLs{{\%}.5f"{}}@*)(*@\HLJLp{,}@*)
    (*@\HLJLnf{mean{\_}squared{\_}error}@*)(*@\HLJLp{(}@*)
        (*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) 
        (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{,}@*)
        (*@\HLJLnf{LS{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{)}@*)
    (*@\HLJLp{)}@*)
(*@\HLJLp{)}@*)
\end{lstlisting}

\begin{lstlisting}
mean squared error: 0.79223
\end{lstlisting}


\subsection{14. (d)}

\begin{lstlisting}
(*@\HLJLnd{@printf}@*)(*@\HLJLp{(}@*)
    (*@\HLJLs{"{}averaged}@*) (*@\HLJLs{mean}@*) (*@\HLJLs{squared}@*) (*@\HLJLs{error:}@*) (*@\HLJLs{{\%}.5f"{}}@*)(*@\HLJLp{,}@*)
    (*@\HLJLnf{mean}@*)(*@\HLJLp{([}@*) 
        (*@\HLJLnf{mean{\_}squared{\_}error}@*)(*@\HLJLp{(}@*)
            (*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) 
            (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{,}@*) 
            (*@\HLJLnf{regSGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{;}@*) (*@\HLJLn{seed}@*)(*@\HLJLoB{=}@*)(*@\HLJLn{i}@*)(*@\HLJLp{)}@*)
        (*@\HLJLp{)}@*)
        (*@\HLJLk{for}@*) (*@\HLJLn{i}@*)(*@\HLJLoB{=}@*)(*@\HLJLni{1}@*)(*@\HLJLoB{:}@*)(*@\HLJLni{1000}@*)
    (*@\HLJLp{])}@*)
(*@\HLJLp{)}@*)
\end{lstlisting}

\begin{lstlisting}
averaged mean squared error: 0.82329
\end{lstlisting}


\subsection{15. (c)}

\begin{lstlisting}
(*@\HLJLnd{@printf}@*)(*@\HLJLp{(}@*)
    (*@\HLJLs{"{}averaged}@*) (*@\HLJLs{cross}@*) (*@\HLJLs{entropy}@*) (*@\HLJLs{error:}@*) (*@\HLJLs{{\%}.5f"{}}@*)(*@\HLJLp{,}@*)
    (*@\HLJLnf{mean}@*)(*@\HLJLp{([}@*) 
        (*@\HLJLnf{cross{\_}entropy{\_}error}@*)(*@\HLJLp{(}@*)
            (*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) 
            (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{,}@*) 
            (*@\HLJLnf{logitSGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{;}@*) (*@\HLJLn{seed}@*)(*@\HLJLoB{=}@*)(*@\HLJLn{i}@*)(*@\HLJLp{)}@*)
        (*@\HLJLp{)}@*)
        (*@\HLJLk{for}@*) (*@\HLJLn{i}@*)(*@\HLJLoB{=}@*)(*@\HLJLni{1}@*)(*@\HLJLoB{:}@*)(*@\HLJLni{1000}@*)
    (*@\HLJLp{])}@*)
(*@\HLJLp{)}@*)
\end{lstlisting}

\begin{lstlisting}
averaged cross entropy error: 0.65725
\end{lstlisting}


$\pagebreak$

\subsection{16. (a)}

\begin{lstlisting}
(*@\HLJLn{w\ensuremath{\_0}}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{LS{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{)}@*)
(*@\HLJLnd{@printf}@*)(*@\HLJLp{(}@*)
    (*@\HLJLs{"{}averaged}@*) (*@\HLJLs{cross}@*) (*@\HLJLs{entropy}@*) (*@\HLJLs{error:}@*) (*@\HLJLs{{\%}.5f"{}}@*)(*@\HLJLp{,}@*)
    (*@\HLJLnf{mean}@*)(*@\HLJLp{([}@*) 
        (*@\HLJLnf{cross{\_}entropy{\_}error}@*)(*@\HLJLp{(}@*)
            (*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) 
            (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{,}@*) 
            (*@\HLJLnf{logitSGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{;}@*) (*@\HLJLn{seed}@*)(*@\HLJLoB{=}@*)(*@\HLJLn{i}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w\ensuremath{\_0}}@*)(*@\HLJLoB{=}@*)(*@\HLJLn{w\ensuremath{\_0}}@*)(*@\HLJLp{)}@*)
        (*@\HLJLp{)}@*)
        (*@\HLJLk{for}@*) (*@\HLJLn{i}@*)(*@\HLJLoB{=}@*)(*@\HLJLni{1}@*)(*@\HLJLoB{:}@*)(*@\HLJLni{1000}@*)
    (*@\HLJLp{])}@*)
(*@\HLJLp{)}@*)
\end{lstlisting}

\begin{lstlisting}
averaged cross entropy error: 0.60527
\end{lstlisting}


\subsection{17. (a)}

\begin{lstlisting}
(*@\HLJLn{test{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{test{\_}y}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{read{\_}data}@*)(*@\HLJLp{(}@*)(*@\HLJLs{"{}../test.txt"{}}@*)(*@\HLJLp{)}@*)

(*@\HLJLn{experiment}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{zeros}@*)(*@\HLJLp{(}@*)(*@\HLJLni{1000}@*)(*@\HLJLp{)}@*)
(*@\HLJLk{for}@*) (*@\HLJLn{i}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{eachindex}@*)(*@\HLJLp{(}@*)(*@\HLJLn{experiment}@*)(*@\HLJLp{)}@*)
    (*@\HLJLn{w}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{logitSGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{;}@*) (*@\HLJLn{seed}@*)(*@\HLJLoB{=}@*)(*@\HLJLn{i}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w\ensuremath{\_0}}@*)(*@\HLJLoB{=}@*)(*@\HLJLn{w\ensuremath{\_0}}@*)(*@\HLJLp{)}@*)
    (*@\HLJLn{experiment}@*)(*@\HLJLp{[}@*)(*@\HLJLn{i}@*)(*@\HLJLp{]}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{abs}@*)(*@\HLJLp{(}@*)(*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*)(*@\HLJLn{train{\_}y}@*)(*@\HLJLp{,}@*)(*@\HLJLn{w}@*)(*@\HLJLp{)}@*)(*@\HLJLoB{-}@*)(*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{test{\_}x}@*)(*@\HLJLp{,}@*)(*@\HLJLn{test{\_}y}@*)(*@\HLJLp{,}@*)(*@\HLJLn{w}@*)(*@\HLJLp{))}@*)
(*@\HLJLk{end}@*)
(*@\HLJLnd{@printf}@*) (*@\HLJLs{"{}averaged}@*) (*@\HLJLs{difference}@*) (*@\HLJLs{of}@*) (*@\HLJLs{train/test}@*) (*@\HLJLs{binary}@*) (*@\HLJLs{error:}@*) (*@\HLJLs{{\%}.5f"{}}@*) (*@\HLJLnf{mean}@*)(*@\HLJLp{(}@*)(*@\HLJLn{experiment}@*)(*@\HLJLp{)}@*)
\end{lstlisting}

\begin{lstlisting}
averaged difference of train/test binary error: 0.03158
\end{lstlisting}


\subsection{18. (b)}

\begin{lstlisting}
(*@\HLJLnd{@printf}@*)(*@\HLJLp{(}@*)
    (*@\HLJLs{"{}difference}@*) (*@\HLJLs{of}@*) (*@\HLJLs{train/test}@*) (*@\HLJLs{binary}@*) (*@\HLJLs{error:}@*) (*@\HLJLs{{\%}.5f"{}}@*)(*@\HLJLp{,}@*)
    (*@\HLJLnf{abs}@*)(*@\HLJLp{(}@*)(*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w\ensuremath{\_0}}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{-}@*) (*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{test{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{test{\_}y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w\ensuremath{\_0}}@*)(*@\HLJLp{))}@*)
(*@\HLJLp{)}@*)
\end{lstlisting}

\begin{lstlisting}
difference of train/test binary error: 0.04000
\end{lstlisting}


$\pagebreak$

\subsection{19. (c)}

\begin{lstlisting}
(*@\HLJLn{train{\_}x{\_}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{test{\_}x{\_}}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{polynomial{\_}transform}@*)(*@\HLJLoB{.}@*)(*@\HLJLp{([}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{test{\_}x}@*)(*@\HLJLp{];}@*) (*@\HLJLn{Q}@*)(*@\HLJLoB{=}@*)(*@\HLJLni{2}@*)(*@\HLJLp{)}@*)
(*@\HLJLn{w}@*) (*@\HLJLoB{=}@*)  (*@\HLJLnf{LS{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x{\_}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{)}@*)

(*@\HLJLnd{@printf}@*)(*@\HLJLp{(}@*)
    (*@\HLJLs{"{}difference}@*) (*@\HLJLs{of}@*) (*@\HLJLs{train/test}@*) (*@\HLJLs{binary}@*) (*@\HLJLs{error:}@*) (*@\HLJLs{{\%}.5f"{}}@*)(*@\HLJLp{,}@*)
    (*@\HLJLnf{abs}@*)(*@\HLJLp{(}@*)(*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x{\_}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{-}@*) (*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{test{\_}x{\_}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{test{\_}y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{))}@*)
(*@\HLJLp{)}@*)
\end{lstlisting}

\begin{lstlisting}
difference of train/test binary error: 0.08250
\end{lstlisting}


\subsection{20. (d)}

\begin{lstlisting}
(*@\HLJLn{train{\_}x{\_}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{test{\_}x{\_}}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{polynomial{\_}transform}@*)(*@\HLJLoB{.}@*)(*@\HLJLp{([}@*)(*@\HLJLn{train{\_}x}@*)(*@\HLJLp{,}@*) (*@\HLJLn{test{\_}x}@*)(*@\HLJLp{];}@*) (*@\HLJLn{Q}@*)(*@\HLJLoB{=}@*)(*@\HLJLni{8}@*)(*@\HLJLp{)}@*)
(*@\HLJLn{w}@*) (*@\HLJLoB{=}@*)  (*@\HLJLnf{LS{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x{\_}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{)}@*)

(*@\HLJLnd{@printf}@*)(*@\HLJLp{(}@*)
    (*@\HLJLs{"{}difference}@*) (*@\HLJLs{of}@*) (*@\HLJLs{train/test}@*) (*@\HLJLs{binary}@*) (*@\HLJLs{error:}@*) (*@\HLJLs{{\%}.5f"{}}@*)(*@\HLJLp{,}@*)
    (*@\HLJLnf{abs}@*)(*@\HLJLp{(}@*)(*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{train{\_}x{\_}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{train{\_}y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{-}@*) (*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{test{\_}x{\_}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{test{\_}y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{))}@*)
(*@\HLJLp{)}@*)
\end{lstlisting}

\begin{lstlisting}
difference of train/test binary error: 0.41500
\end{lstlisting}


$\pagebreak$

\section{Code Reference}

\begin{lstlisting}
(*@\HLJLk{using}@*) (*@\HLJLn{Printf}@*)

(*@\HLJLk{import}@*) (*@\HLJLn{DelimitedFiles}@*)(*@\HLJLoB{:}@*) (*@\HLJLn{readdlm}@*)
(*@\HLJLk{using}@*) (*@\HLJLn{Distributions}@*)(*@\HLJLp{,}@*) (*@\HLJLn{Random}@*)

(*@\HLJLk{function}@*) (*@\HLJLnf{read{\_}data}@*)(*@\HLJLp{(}@*)(*@\HLJLn{path}@*)(*@\HLJLp{)}@*)
    (*@\HLJLn{data}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{readdlm}@*)(*@\HLJLp{(}@*)(*@\HLJLn{path}@*)(*@\HLJLp{,}@*) (*@\HLJLsc{{\textquotesingle}{\textbackslash}t{\textquotesingle}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{Float64}@*)(*@\HLJLp{,}@*) (*@\HLJLsc{{\textquotesingle}{\textbackslash}n{\textquotesingle}}@*)(*@\HLJLp{)}@*)
    (*@\HLJLn{features}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{hcat}@*)(*@\HLJLp{(}@*)(*@\HLJLnf{ones}@*)(*@\HLJLp{(}@*)(*@\HLJLnf{size}@*)(*@\HLJLp{(}@*)(*@\HLJLn{data}@*)(*@\HLJLp{,}@*) (*@\HLJLni{1}@*)(*@\HLJLp{)),}@*) (*@\HLJLn{data}@*)(*@\HLJLp{[}@*)(*@\HLJLoB{:}@*)(*@\HLJLp{,}@*) (*@\HLJLk{begin}@*)(*@\HLJLoB{:}@*)(*@\HLJLk{end}@*)(*@\HLJLoB{-}@*)(*@\HLJLni{1}@*)(*@\HLJLp{])}@*) 
    (*@\HLJLn{label}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{data}@*)(*@\HLJLp{[}@*)(*@\HLJLoB{:}@*)(*@\HLJLp{,}@*) (*@\HLJLk{end}@*)(*@\HLJLp{]}@*)
    
    (*@\HLJLk{return}@*) (*@\HLJLn{features}@*)(*@\HLJLp{,}@*) (*@\HLJLn{label}@*)
(*@\HLJLk{end}@*)

(*@\HLJLnf{mean{\_}squared{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{mean}@*)(*@\HLJLp{((}@*)(*@\HLJLn{X}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{w}@*)(*@\HLJLoB{-}@*)(*@\HLJLn{y}@*)(*@\HLJLp{)}@*)(*@\HLJLoB{.{\textasciicircum}}@*)(*@\HLJLni{2}@*)(*@\HLJLp{)}@*)
(*@\HLJLnf{cross{\_}entropy{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLoB{-}@*)(*@\HLJLnf{mean}@*)(*@\HLJLp{(}@*)(*@\HLJLn{log}@*)(*@\HLJLoB{.}@*)(*@\HLJLp{(}@*)(*@\HLJLn{logistic}@*)(*@\HLJLoB{.}@*)(*@\HLJLp{(}@*)(*@\HLJLn{y}@*) (*@\HLJLoB{.*}@*) (*@\HLJLn{X}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{w}@*)(*@\HLJLp{)))}@*)

(*@\HLJLnf{check{\_}sign}@*)(*@\HLJLp{(}@*)(*@\HLJLn{a}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{a}@*) (*@\HLJLoB{==}@*) (*@\HLJLnfB{0.}@*) (*@\HLJLoB{?}@*) (*@\HLJLnfB{1.}@*) (*@\HLJLoB{:}@*) (*@\HLJLnf{sign}@*)(*@\HLJLp{(}@*)(*@\HLJLn{a}@*)(*@\HLJLp{)}@*)
(*@\HLJLnf{binary{\_}error}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{mean}@*)(*@\HLJLp{(}@*)(*@\HLJLn{check{\_}sign}@*)(*@\HLJLoB{.}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{w}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{.!=}@*) (*@\HLJLn{y}@*)(*@\HLJLp{)}@*)

(*@\HLJLnf{LS{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{inv}@*)(*@\HLJLp{(}@*)(*@\HLJLnf{transpose}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{)}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{X}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{*}@*) (*@\HLJLp{(}@*)(*@\HLJLnf{transpose}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{)}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{y}@*)(*@\HLJLp{)}@*)

(*@\HLJLk{function}@*) (*@\HLJLnf{SGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{sg}@*)(*@\HLJLp{;}@*) (*@\HLJLn{it}@*)(*@\HLJLoB{=}@*)(*@\HLJLni{800}@*)(*@\HLJLp{,}@*) (*@\HLJLn{\ensuremath{\eta}}@*)(*@\HLJLoB{=}@*)(*@\HLJLnfB{0.001}@*)(*@\HLJLp{,}@*) (*@\HLJLn{seed}@*)(*@\HLJLoB{=}@*)(*@\HLJLni{20230420}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w\ensuremath{\_0}}@*)(*@\HLJLoB{=}@*)(*@\HLJLn{nothing}@*)(*@\HLJLp{)}@*)
    (*@\HLJLn{Random}@*)(*@\HLJLoB{.}@*)(*@\HLJLnf{seed!}@*)(*@\HLJLp{(}@*)(*@\HLJLn{seed}@*)(*@\HLJLp{)}@*)
    (*@\HLJLn{w}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{isa}@*)(*@\HLJLp{(}@*)(*@\HLJLn{w\ensuremath{\_0}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{Nothing}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{?}@*) (*@\HLJLnf{zeros}@*)(*@\HLJLp{(}@*)(*@\HLJLnf{size}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLni{2}@*)(*@\HLJLp{))}@*) (*@\HLJLoB{:}@*) (*@\HLJLn{w\ensuremath{\_0}}@*)
    (*@\HLJLn{idx}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{sample}@*)(*@\HLJLp{(}@*)(*@\HLJLni{1}@*)(*@\HLJLoB{:}@*)(*@\HLJLnf{size}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLni{1}@*)(*@\HLJLp{),}@*) (*@\HLJLn{it}@*)(*@\HLJLp{,}@*) (*@\HLJLn{replace}@*)(*@\HLJLoB{=}@*)(*@\HLJLkc{true}@*)(*@\HLJLp{)}@*)
    (*@\HLJLk{for}@*) (*@\HLJLn{i}@*) (*@\HLJLoB{=}@*) (*@\HLJLni{1}@*)(*@\HLJLoB{:}@*)(*@\HLJLn{it}@*)
        (*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y\ensuremath{\_i}}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{X}@*)(*@\HLJLp{[}@*)(*@\HLJLn{idx}@*)(*@\HLJLp{[}@*)(*@\HLJLn{i}@*)(*@\HLJLp{],}@*) (*@\HLJLoB{:}@*)(*@\HLJLp{],}@*) (*@\HLJLn{y}@*)(*@\HLJLp{[}@*)(*@\HLJLn{idx}@*)(*@\HLJLp{[}@*)(*@\HLJLn{i}@*)(*@\HLJLp{]]}@*)
        (*@\HLJLn{w}@*) (*@\HLJLoB{-=}@*) (*@\HLJLn{\ensuremath{\eta}}@*) (*@\HLJLoB{*}@*) (*@\HLJLnf{sg}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y\ensuremath{\_i}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{)}@*)
    (*@\HLJLk{end}@*)
    
    (*@\HLJLk{return}@*) (*@\HLJLn{w}@*)
(*@\HLJLk{end}@*)

(*@\HLJLnf{reg{\_}stochastic{\_}gradient}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y\ensuremath{\_i}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLni{2}@*) (*@\HLJLoB{*}@*) (*@\HLJLp{(}@*)(*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLoB{*}@*)(*@\HLJLnf{transpose}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLp{)}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{w}@*) (*@\HLJLoB{-}@*) (*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{y\ensuremath{\_i}}@*)(*@\HLJLp{)}@*)
(*@\HLJLnf{regSGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{;}@*) (*@\HLJLn{kwargs}@*)(*@\HLJLoB{...}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{SGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{reg{\_}stochastic{\_}gradient}@*)(*@\HLJLp{;}@*) (*@\HLJLn{kwargs}@*)(*@\HLJLoB{...}@*)(*@\HLJLp{)}@*)

(*@\HLJLnf{logistic}@*)(*@\HLJLp{(}@*)(*@\HLJLn{x}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLni{1}@*) (*@\HLJLoB{/}@*) (*@\HLJLp{(}@*)(*@\HLJLni{1}@*)(*@\HLJLoB{+}@*)(*@\HLJLnf{exp}@*)(*@\HLJLp{(}@*)(*@\HLJLoB{-}@*)(*@\HLJLn{x}@*)(*@\HLJLp{))}@*)
(*@\HLJLnf{logit{\_}stochastic{\_}gradient}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y\ensuremath{\_i}}@*)(*@\HLJLp{,}@*) (*@\HLJLn{w}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{logistic}@*)(*@\HLJLp{(}@*)(*@\HLJLoB{-}@*)(*@\HLJLn{y\ensuremath{\_i}}@*)(*@\HLJLoB{*}@*)(*@\HLJLnf{transpose}@*)(*@\HLJLp{(}@*)(*@\HLJLn{w}@*)(*@\HLJLp{)}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{*}@*) (*@\HLJLp{(}@*)(*@\HLJLoB{-}@*)(*@\HLJLn{y\ensuremath{\_i}}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{X\ensuremath{\_i}}@*)(*@\HLJLp{)}@*)
(*@\HLJLnf{logitSGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{;}@*) (*@\HLJLn{kwargs}@*)(*@\HLJLoB{...}@*)(*@\HLJLp{)}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{SGD{\_}estimator}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLn{y}@*)(*@\HLJLp{,}@*) (*@\HLJLn{logit{\_}stochastic{\_}gradient}@*)(*@\HLJLp{;}@*) (*@\HLJLn{kwargs}@*)(*@\HLJLoB{...}@*)(*@\HLJLp{)}@*)

(*@\HLJLk{function}@*) (*@\HLJLnf{polynomial{\_}transform}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{;}@*) (*@\HLJLn{Q}@*)(*@\HLJLp{)}@*)
    (*@\HLJLn{d}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{size}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLni{2}@*)(*@\HLJLp{)}@*)(*@\HLJLoB{-}@*)(*@\HLJLni{1}@*)
    (*@\HLJLn{X{\_}}@*) (*@\HLJLoB{=}@*) (*@\HLJLnf{Matrix}@*)(*@\HLJLp{{\{}}@*)(*@\HLJLn{Float64}@*)(*@\HLJLp{{\}}(}@*)(*@\HLJLn{undef}@*)(*@\HLJLp{,}@*) (*@\HLJLnf{size}@*)(*@\HLJLp{(}@*)(*@\HLJLn{X}@*)(*@\HLJLp{,}@*) (*@\HLJLni{1}@*)(*@\HLJLp{),}@*) (*@\HLJLn{Q}@*)(*@\HLJLoB{*}@*)(*@\HLJLn{d}@*)(*@\HLJLoB{+}@*)(*@\HLJLni{1}@*)(*@\HLJLp{)}@*)
    (*@\HLJLn{X{\_}}@*)(*@\HLJLp{[}@*)(*@\HLJLoB{:}@*)(*@\HLJLp{,}@*) (*@\HLJLk{begin}@*)(*@\HLJLoB{:}@*)(*@\HLJLn{d}@*)(*@\HLJLoB{+}@*)(*@\HLJLni{1}@*)(*@\HLJLp{]}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{X}@*)(*@\HLJLp{;}@*) (*@\HLJLn{X}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{X}@*)(*@\HLJLp{[}@*)(*@\HLJLoB{:}@*)(*@\HLJLp{,}@*) (*@\HLJLk{begin}@*)(*@\HLJLoB{+}@*)(*@\HLJLni{1}@*)(*@\HLJLoB{:}@*)(*@\HLJLk{end}@*)(*@\HLJLp{]}@*)

    (*@\HLJLn{beg}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{d}@*) (*@\HLJLoB{+}@*) (*@\HLJLni{2}@*)
    (*@\HLJLk{for}@*) (*@\HLJLn{q}@*) (*@\HLJLoB{=}@*) (*@\HLJLni{2}@*)(*@\HLJLoB{:}@*)(*@\HLJLn{Q}@*)
        (*@\HLJLn{en}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{beg}@*) (*@\HLJLoB{+}@*) (*@\HLJLn{d}@*) (*@\HLJLoB{-}@*) (*@\HLJLni{1}@*)
        (*@\HLJLn{X{\_}}@*)(*@\HLJLp{[}@*)(*@\HLJLoB{:}@*)(*@\HLJLp{,}@*) (*@\HLJLn{beg}@*)(*@\HLJLoB{:}@*)(*@\HLJLn{en}@*)(*@\HLJLp{]}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{X}@*) (*@\HLJLoB{.{\textasciicircum}}@*) (*@\HLJLn{q}@*)
        (*@\HLJLn{beg}@*) (*@\HLJLoB{=}@*) (*@\HLJLn{en}@*) (*@\HLJLoB{+}@*) (*@\HLJLni{1}@*)
    (*@\HLJLk{end}@*)

    (*@\HLJLk{return}@*) (*@\HLJLn{X{\_}}@*)
(*@\HLJLk{end}@*)
\end{lstlisting}


\end{document}